{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "from scipy import sparse as ssp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gini(y_true, y_pred):\n",
    "    # check and get number of samples\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    n_samples = y_true.shape[0]\n",
    "\n",
    "    # sort rows on prediction column\n",
    "    # (from largest to smallest)\n",
    "    arr = np.array([y_true, y_pred]).transpose()\n",
    "    true_order = arr[arr[:, 0].argsort()][::-1, 0]\n",
    "    pred_order = arr[arr[:, 1].argsort()][::-1, 0]\n",
    "\n",
    "    # get Lorenz curves\n",
    "    L_true = np.cumsum(true_order) * 1. / np.sum(true_order)\n",
    "    L_pred = np.cumsum(pred_order) * 1. / np.sum(pred_order)\n",
    "    L_ones = np.linspace(1 / n_samples, 1, n_samples)\n",
    "\n",
    "    # get Gini coefficients (area between curves)\n",
    "    G_true = np.sum(L_ones - L_true)\n",
    "    G_pred = np.sum(L_ones - L_pred)\n",
    "\n",
    "    # normalize to true Gini coefficient\n",
    "    return G_pred * 1. / G_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'gini', Gini(labels, preds), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFOLDS = 5\n",
    "kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=218)\n",
    "cv_only = True\n",
    "save_cv = True\n",
    "full_train = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ssp.load_npz(\"./data/train.npz\")\n",
    "X_test = ssp.load_npz(\"./data/test.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "train_label = train['target']\n",
    "train_id = train['id']\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "test_id = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_customer(X, train_label, k_fold, final_cv_train, final_cv_pred, cv_train, cv_pred, seed = None):\n",
    "    kf = k_fold.split(X, train_label)\n",
    "    \n",
    "    best_trees = []\n",
    "    fold_scores = []\n",
    "    \n",
    "    for i, (train_fold, validate) in enumerate(kf):\n",
    "        X_train, X_validate, label_train, label_validate = X[train_fold, :], X[validate, :], train_label[train_fold], train_label[validate]       \n",
    "        model = lgbm_(X_train, X_validate, label_train, label_validate,seed)\n",
    "        cv_pred += model.predict(X_test, num_iteration=model.best_iteration)\n",
    "        cv_train[validate] += model.predict(X_validate)\n",
    "        \n",
    "    cv_pred /= NFOLDS\n",
    "    final_cv_train += cv_train\n",
    "    final_cv_pred += cv_pred    \n",
    "    \n",
    "    print (\"cv score:\", Gini(train_label, cv_train))\n",
    "    print( \"current score:\", Gini(train_label, final_cv_train / (s + 1.)), s+1)  # everage the in a loop  \n",
    "#         print(fold_scores)\n",
    "#     print(\"the best iteration is around: \", np.mean(best_trees)) # know \n",
    "#     x_score.append(Gini(train_label, cv_train))\n",
    "    print(\"-----------------------------------------------------------------------------------------------------\")\n",
    "    return final_cv_train, final_cv_pred\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_( X_train, X_validate, label_train, label_validate,seed):\n",
    "    learning_rate = 0.1\n",
    "    num_leaves = 15\n",
    "    min_data_in_leaf = 2000\n",
    "    feature_fraction = 0.6\n",
    "    num_boost_round = 1000 #M \n",
    "    tot_iter = 16\n",
    "    \n",
    "    params = {\"objective\": \"binary\",\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"learning_rate\": learning_rate,\n",
    "          \"num_leaves\": num_leaves,\n",
    "           \"max_bin\": 256,\n",
    "          \"feature_fraction\": feature_fraction,\n",
    "          \"verbosity\": 0,\n",
    "          \"drop_rate\": 0.1,\n",
    "          \"is_unbalance\": False,\n",
    "          \"max_drop\": 50,\n",
    "          \"min_child_samples\": 10,\n",
    "          \"min_child_weight\": 150,\n",
    "          \"min_split_gain\": 0,\n",
    "          \"subsample\": 0.9\n",
    "          }\n",
    "    params['seed'] = seed\n",
    "    \n",
    "    dtrain = lgbm.Dataset(X_train, label_train)\n",
    "    dvalid = lgbm.Dataset(X_validate, label_validate, reference=dtrain)\n",
    "    bst = lgbm.train(params, dtrain, num_boost_round, valid_sets=dvalid, feval=evalerror, verbose_eval=100,\n",
    "                    early_stopping_rounds=100)\n",
    "    best_trees.append(bst.best_iteration) # the index of iteration  \n",
    "    \n",
    "    return bst\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_aver (X, train_label,test_id, k_fold, tot_iter):\n",
    "    x_score = []\n",
    "    cv_train = np.zeros(len(train_label))\n",
    "    cv_pred = np.zeros(len(test_id))\n",
    "    final_cv_train = np.zeros(len(train_label))\n",
    "    final_cv_pred = np.zeros(len(test_id))\n",
    "    for s in range(tot_iter):\n",
    "        cv_train = np.zeros(len(train_label))\n",
    "        cv_pred = np.zeros(len(test_id))\n",
    "#         seed = s \n",
    "        final_cv_train, final_cv_pred = cv_customer(X, train_label, k_fold, final_cv_train, final_cv_pred,cv_train, cv_pred,seed=s)\n",
    "    return final_cv_train, final_cv_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.15159\tvalid_0's gini: 0.291863\n",
      "[200]\tvalid_0's binary_logloss: 0.151468\tvalid_0's gini: 0.29491\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's binary_logloss: 0.151457\tvalid_0's gini: 0.295075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.152123\tvalid_0's gini: 0.272679\n",
      "[200]\tvalid_0's binary_logloss: 0.152038\tvalid_0's gini: 0.275581\n",
      "[300]\tvalid_0's binary_logloss: 0.152089\tvalid_0's gini: 0.276195\n",
      "Early stopping, best iteration is:\n",
      "[224]\tvalid_0's binary_logloss: 0.152015\tvalid_0's gini: 0.276851\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.151974\tvalid_0's gini: 0.277978\n",
      "[200]\tvalid_0's binary_logloss: 0.151926\tvalid_0's gini: 0.280307\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's binary_logloss: 0.151902\tvalid_0's gini: 0.280395\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.151832\tvalid_0's gini: 0.283252\n",
      "[200]\tvalid_0's binary_logloss: 0.151762\tvalid_0's gini: 0.285428\n",
      "Early stopping, best iteration is:\n",
      "[194]\tvalid_0's binary_logloss: 0.151744\tvalid_0's gini: 0.285738\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.151486\tvalid_0's gini: 0.289094\n",
      "[200]\tvalid_0's binary_logloss: 0.151439\tvalid_0's gini: 0.290154\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's binary_logloss: 0.151433\tvalid_0's gini: 0.290764\n",
      "cv score: 0.2856619948011391\n",
      "current score: 0.2856619948011391 1\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.151604\tvalid_0's gini: 0.290167\n",
      "[200]\tvalid_0's binary_logloss: 0.15153\tvalid_0's gini: 0.292546\n",
      "[300]\tvalid_0's binary_logloss: 0.151569\tvalid_0's gini: 0.291396\n",
      "Early stopping, best iteration is:\n",
      "[215]\tvalid_0's binary_logloss: 0.151501\tvalid_0's gini: 0.293575\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.152153\tvalid_0's gini: 0.2722\n",
      "[200]\tvalid_0's binary_logloss: 0.152051\tvalid_0's gini: 0.27555\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's binary_logloss: 0.152041\tvalid_0's gini: 0.27574\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.152063\tvalid_0's gini: 0.276269\n",
      "[200]\tvalid_0's binary_logloss: 0.151979\tvalid_0's gini: 0.279146\n",
      "[300]\tvalid_0's binary_logloss: 0.151971\tvalid_0's gini: 0.279805\n",
      "Early stopping, best iteration is:\n",
      "[286]\tvalid_0's binary_logloss: 0.151958\tvalid_0's gini: 0.279855\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.151822\tvalid_0's gini: 0.284346\n",
      "[200]\tvalid_0's binary_logloss: 0.151739\tvalid_0's gini: 0.287288\n",
      "[300]\tvalid_0's binary_logloss: 0.151824\tvalid_0's gini: 0.285641\n",
      "Early stopping, best iteration is:\n",
      "[204]\tvalid_0's binary_logloss: 0.151737\tvalid_0's gini: 0.287408\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.151437\tvalid_0's gini: 0.290417\n",
      "[200]\tvalid_0's binary_logloss: 0.151376\tvalid_0's gini: 0.292036\n",
      "Early stopping, best iteration is:\n",
      "[165]\tvalid_0's binary_logloss: 0.151364\tvalid_0's gini: 0.292387\n",
      "cv score: 0.2857025892457676\n",
      "current score: 0.2871680876619639 1\n",
      "-----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tot_iteration = 2\n",
    "final_cv_train, final_cv_pred = model_aver(X, train_label,test_id, kfold, tot_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.15159\tvalid_0's gini: 0.291863\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-b67ff66068e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mdtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mdvalid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_validate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_validate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             bst = lgbm.train(params, dtrain, num_boost_round, valid_sets=dvalid, feval=evalerror, verbose_eval=100,\n\u001b[0m\u001b[0;32m     45\u001b[0m                             early_stopping_rounds=100)\n\u001b[0;32m     46\u001b[0m             \u001b[0mbest_trees\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# the index of iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pd_env\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m             \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcallbacks_after_iter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pd_env\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36meval_valid\u001b[1;34m(self, feval)\u001b[0m\n\u001b[0;32m   2185\u001b[0m             \u001b[0mList\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2186\u001b[0m         \"\"\"\n\u001b[1;32m-> 2187\u001b[1;33m         return [item for i in range_(1, self.__num_dataset)\n\u001b[0m\u001b[0;32m   2188\u001b[0m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[0;32m   2189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pd_env\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2186\u001b[0m         \"\"\"\n\u001b[0;32m   2187\u001b[0m         return [item for i in range_(1, self.__num_dataset)\n\u001b[1;32m-> 2188\u001b[1;33m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[0m\u001b[0;32m   2189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2190\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pd_env\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[1;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[0mcur_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_idx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2658\u001b[1;33m             \u001b[0mfeval_ret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__inner_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2659\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval_ret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0meval_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_higher_better\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeval_ret\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-3865498e839d>\u001b[0m in \u001b[0;36mevalerror\u001b[1;34m(preds, dtrain)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevalerror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;34m'gini'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGini\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-39c85e167c15>\u001b[0m in \u001b[0;36mGini\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtrue_order\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mpred_order\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# get Lorenz curves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "num_leaves = 15\n",
    "min_data_in_leaf = 2000\n",
    "feature_fraction = 0.6\n",
    "num_boost_round = 1000 #M \n",
    "tot_iter = 16\n",
    "\n",
    "params = {\"objective\": \"binary\",\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"learning_rate\": learning_rate,\n",
    "          \"num_leaves\": num_leaves,\n",
    "           \"max_bin\": 256,\n",
    "          \"feature_fraction\": feature_fraction,\n",
    "          \"verbosity\": 0,\n",
    "          \"drop_rate\": 0.1,\n",
    "          \"is_unbalance\": False,\n",
    "          \"max_drop\": 50,\n",
    "          \"min_child_samples\": 10,\n",
    "          \"min_child_weight\": 150,\n",
    "          \"min_split_gain\": 0,\n",
    "          \"subsample\": 0.9\n",
    "          }\n",
    "\n",
    "x_score = []\n",
    "final_cv_train = np.zeros(len(train_label))\n",
    "final_cv_pred = np.zeros(len(test_id))\n",
    "for s in range(tot_iter):\n",
    "    cv_train = np.zeros(len(train_label))\n",
    "    cv_pred = np.zeros(len(test_id))\n",
    "\n",
    "    params['seed'] = s\n",
    "\n",
    "    if cv_only: \n",
    "        kf = kfold.split(X, train_label)\n",
    "\n",
    "        best_trees = []\n",
    "        fold_scores = []\n",
    "\n",
    "        for i, (train_fold, validate) in enumerate(kf):\n",
    "            X_train, X_validate, label_train, label_validate = \\\n",
    "                X[train_fold, :], X[validate, :], train_label[train_fold], train_label[validate]\n",
    "            dtrain = lgbm.Dataset(X_train, label_train)\n",
    "            dvalid = lgbm.Dataset(X_validate, label_validate, reference=dtrain)\n",
    "            bst = lgbm.train(params, dtrain, num_boost_round, valid_sets=dvalid, feval=evalerror, verbose_eval=100,\n",
    "                            early_stopping_rounds=100)\n",
    "            best_trees.append(bst.best_iteration) # the index of iteration \n",
    "            cv_pred += bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "            cv_train[validate] += bst.predict(X_validate)\n",
    "\n",
    "            score = Gini(label_validate, cv_train[validate])\n",
    "#             fold_scores.append(score)  #the gini in each fold; i.e. 5 in total; just take a look \n",
    "\n",
    "        cv_pred /= NFOLDS\n",
    "        final_cv_train += cv_train\n",
    "        final_cv_pred += cv_pred\n",
    "\n",
    "        print (\"cv score:\", Gini(train_label, cv_train))\n",
    "        print( \"current score:\", Gini(train_label, final_cv_train / (s + 1.)), s+1)  # everage the in a loop  \n",
    "#         print(fold_scores)\n",
    "        print(\"the best iteration is around: \", np.mean(best_trees)) # know \n",
    "        x_score.append(Gini(train_label, cv_train))\n",
    "        print(\"-----------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2857927260519864"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([0.2935750199212115, 0.2757395481512084, 0.2798546933254257, 0.2874076703284102, 0.2923866985336762])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'id': test_id, 'target': final_cv_pred / tot_iter}).to_csv('./model/lgbm3_pred_avg.csv', index=False)\n",
    "pd.DataFrame({'id': train_id, 'target': final_cv_train / tot_iter}).to_csv('./model/lgbm3_cv_avg.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, train_label,shuffle=True,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2603a448760>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(random_state=0, max_iter=100, penalty = 'l2', solver='liblinear',C=1, n_jobs=None).fit(x_train, y_train)\n",
    "plot_confusion_matrix(estimator = lr_clf, X=x_test, y_true = y_test,normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
